# MCPサーバー (FastMCP) ツール選択実験

## 概要
LLMが、FastMCPで作成したツールを呼び出す際に、ツールの**関数名**と**docstring（コメント）**をどのように参照するかを検証した。

### 検証パターン
1. **関数名: 意味なし、docstring: 意味あり**
2. **関数名: 意味あり（ダミー）、docstring: 意味あり（矛盾）**

### 実験結果の要約
**LLMは関数名とdocstringの両方を参照するが、関数名の方が優先される傾向がある。**

- docstringは確実に参照される
- 関数名とdocstringが矛盾する場合、関数名が優先される

---

## 実験1: 関数名に意味なし、docstringに意味あり

### 使用したツール定義
```python
@server.tool()
def alpha(x: str) -> str:
    """
    都市名を受け取り、その都市の天気を説明する。
    """
    return f"{x} の天気は晴れです"


@server.tool()
def beta(x: str) -> str:
    """
    文字列で与えられた数値を処理する。
    """
    return "計算結果です"


@server.tool()
def gamma(x: str) -> str:
    """
    都市名を受け取り、その都市の緯度と経度を返す。
    """
    return f"{x} の緯度はxx、経度はooです"
```

### 実験結果
```
============================================================
=== LLM Tool Selection Experiment ===
============================================================

【実験1】天気についての質問
質問: 「東京の天気を教えて」
✅ LLMが選択したツール: alpha
   引数: {"x":"東京"}
   結果: 東京 の天気は晴れです

【実験2】計算についての質問
質問: 「100 + 200を計算して」
✅ LLMが選択したツール: beta
   引数: {"x":"100 + 200"}
   結果: 計算結果です

【実験3】曖昧な質問
質問: 「東京について教えて」
✅ LLMが選択したツール: alpha
   引数: {"x": "東京"}
```

---

## 実験2: 関数名に意味あり（矛盾）、docstringに意味あり

### 使用したツール定義
```python
@server.tool()
def coordinate_city(x: str) -> str:
    """
    都市名を受け取り、その都市の天気を説明する。
    """
    return f"{x} の天気は晴れです"


@server.tool()
def weather_of_city(x: str) -> str:
    """
    文字列で与えられた数値を処理する。
    """
    return "計算結果です"


@server.tool()
def weather_city(x: str) -> str:
    """
    都市名を受け取り、その都市の緯度と経度を返す。
    """
    return f"{x} の緯度はxx、経度はooです"
```

### 実験結果
```
============================================================
=== LLM Tool Selection Experiment ===
============================================================

【実験1】天気についての質問
質問: 「東京の天気を教えて」
✅ LLMが選択したツール: weather_city
   引数: {"x":"東京"}
   結果: 東京 の緯度はxx、経度はooです

【実験2】計算についての質問
質問: 「100 + 200を計算して」
❌ ツールが呼び出されませんでした
   理由: どの関数名も計算に関連していない

【実験3】曖昧な質問
質問: 「東京について教えて」
✅ LLMが選択したツール: weather_city
   引数: {"x": "東京"}
```
---

### 実験環境
- **MCPライブラリ**: FastMCP
- **LLMモデル**: GPT-4o-mini (OpenAI)
- **プロトコル**: MCP (Model Context Protocol) over stdio